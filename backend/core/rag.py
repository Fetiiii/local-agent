import os
import uuid
from typing import List, Dict, Any
import chromadb
from chromadb.utils import embedding_functions
from sentence_transformers import SentenceTransformer

# ChromaDB ve Model AyarlarÄ±
VECTOR_DB_PATH = os.path.join(os.getcwd(), "data", "vector_store")
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"

class RAGManager:
    def __init__(self):
        print(f"ğŸ§  RAG Manager BaÅŸlatÄ±lÄ±yor ({VECTOR_DB_PATH})...")
        
        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(VECTOR_DB_PATH, exist_ok=True)
        
        # ChromaDB Client (Persistent)
        self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
        
        # Embedding Function (Sentence-Transformers kullanÄ±yoruz, hafif ve hÄ±zlÄ±)
        # ChromaDB'nin built-in fonksiyonu yerine manuel yÃ¶netmek daha stabil sonuÃ§ veriyor bazen,
        # ama burada Chroma'nÄ±n utility'sini kullanmak en kolayÄ±.
        self.ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL_NAME)
        
        # Koleksiyonu al veya yarat
        self.collection = self.client.get_or_create_collection(
            name="local_knowledge",
            embedding_function=self.ef
        )

    def add_document(self, text: str, source: str):
        """
        Metni parÃ§alara (chunk) ayÄ±rÄ±r ve VektÃ¶r DB'ye ekler.
        """
        chunks = self._split_text(text)
        
        if not chunks:
            return 0
            
        ids = [str(uuid.uuid4()) for _ in chunks]
        metadatas = [{"source": source} for _ in chunks]
        
        # DB'ye ekle
        self.collection.add(
            documents=chunks,
            metadatas=metadatas,
            ids=ids
        )
        print(f"ğŸ“š {len(chunks)} parÃ§a hafÄ±zaya eklendi: {source}")
        return len(chunks)

    def search(self, query: str, n_results: int = 3) -> List[str]:
        """
        Sorgu ile en alakalÄ± metin parÃ§alarÄ±nÄ± getirir.
        """
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )
        
        # ChromaDB sonucu karmaÅŸÄ±k bir dict dÃ¶ner, biz sadece textleri alalÄ±m
        # results['documents'] -> [[doc1, doc2, ...]]
        if results and results['documents']:
            return results['documents'][0]
        return []

    def _split_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """
        Basit ama etkili bir chunking (parÃ§alama) algoritmasÄ±.
        RecursiveCharacterTextSplitter mantÄ±ÄŸÄ±na benzer.
        """
        if not text:
            return []
            
        chunks = []
        start = 0
        text_len = len(text)
        
        while start < text_len:
            end = start + chunk_size
            
            # EÄŸer sona gelmediysek ve kelime ortasÄ±ndaysak, en yakÄ±n boÅŸluÄŸa geri git
            if end < text_len:
                # Geriye doÄŸru boÅŸluk ara
                while end > start and text[end] not in [' ', '\n', '.', ',']:
                    end -= 1
                # EÄŸer hiÃ§ boÅŸluk bulamazsa mecburen chunk_size kadar kes (kelime Ã§ok uzunsa)
                if end == start:
                    end = start + chunk_size
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # Overlap (Ã¶rtÃ¼ÅŸme) payÄ± ile bir sonraki parÃ§aya geÃ§
            start = end - overlap
            
        return chunks

    def clear_memory(self):
        """HafÄ±zayÄ± temizler (Yeni sohbet iÃ§in opsiyonel)."""
        self.client.delete_collection("local_knowledge")
        self.collection = self.client.get_or_create_collection(
            name="local_knowledge",
            embedding_function=self.ef
        )
